class SarsaAgent:
  def __init__(self, env, alpha=0.1, gamma=0.9, epsilon=0.1):
    self.env = env
    self.alpha = alpha
    self.gamma = gamma
    self.epsilon = epsilon
    self.q_table = {}

    for r in range(env.height):
      for c in range(env.width):
        state = (r, c)
        if state not in env.obstacles and state != env.goal_state:
          self.q_table[state] = np.zeros(len(env.actions))
        elif state == env.goal_state:
          self.q_table[state] = np.zeros(len(env.actions))

  def choose_action(self, state):
    if np.random.uniform(0, 1) < self.epsilon:
      return np.random.choice(len(self.env.actions))
    else:
      if state in self.q_table:
        best_actions = np.where(self.q_table[state] == np.max(self.q_table[state]))[0]
        return np.random.choice(best_actions)
      else:
        return np.random.choice(len(self.env.actions))

  def learn(self, state, action, reward, next_state, next_action):
    if state not in self.q_table:
      return

    current_q = self.q_table[state][action]

    if next_state in self.q_table:
      next_q = self.q_table[next_state][next_action]
    else:
      next_q = 0

    # SARSA formula
    new_q = current_q + self.alpha * (reward + self.gamma * next_q - current_q)

    # Update Q-table
    self.q_table[state][action] = new_q

sarsa_agent = SarsaAgent(env)

num_episodes = 1000

for episode in range(num_episodes):
  state = env.reset()
  action = sarsa_agent.choose_action(state)
  done = False
  total_reward = 0

  for i in range(100):
    action = sarsa_agent.choose_action(state)
    next_state, reward, done = env.step(action)
    next_action = sarsa_agent.choose_action(next_state)
    sarsa_agent.learn(state, action, reward, next_state, next_action)
    state = next_state
    action = next_action
    total_reward += reward
    if done:
      break

  if (episode + 1) % 100 == 0:
    print(f"Episode : {episode + 1} : Total Reward = {total_reward}")

state = env.reset()
env.render()
done = False
while not done:
  if state in sarsa_agent.q_table:
    action = np.argmax(sarsa_agent.q_table[state])
  else:
    action = np.random.choice(len(env.actions))
  state, reward, done = env.step(action)
  env.render()
  print(f"State : {state}, Reward : {reward}, Done : {done}")
